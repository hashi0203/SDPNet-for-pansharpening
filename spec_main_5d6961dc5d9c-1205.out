WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
source_pan_data shape: (4914, 264, 264, 1)
gt_data shape: (4914, 264, 264, 4)
data shape: (4914, 264, 264, 5)
Epoches: 20, Batch_size: 10
Train images number 4914, Batches: 491.

Train set has been trimmed 4 samples...

2021-12-05 02:58:30.715597: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-05 02:58:31.217918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78874 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:27:00.0, compute capability: 8.0
out shape: (10, 66, 66, 4)
2021-12-05 02:58:36.190264: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301
Epoch:1/20: step:100, lr:0.0019348845, loss:0.071209654, elapsed_time:0:00:10.901830

Epoch:1/20: step:200, lr:0.001871889, loss:0.048087757, elapsed_time:0:00:14.507417

Epoch:1/20: step:300, lr:0.0018109444, loss:0.030794142, elapsed_time:0:00:17.912496

Epoch:1/20: step:400, lr:0.0017519841, loss:0.01435696, elapsed_time:0:00:21.484599

Epoch:2/20: step:500, lr:0.0016949435, loss:0.012910577, elapsed_time:0:00:27.974912

Epoch:2/20: step:600, lr:0.0016397599, loss:0.010438159, elapsed_time:0:00:31.184424

Epoch:2/20: step:700, lr:0.001586373, loss:0.006544054, elapsed_time:0:00:34.421257

Epoch:2/20: step:800, lr:0.001534724, loss:0.019021656, elapsed_time:0:00:37.454611

Epoch:2/20: step:900, lr:0.0014847568, loss:0.0074681807, elapsed_time:0:00:40.553266

Epoch:3/20: step:1000, lr:0.0014364165, loss:0.0072093084, elapsed_time:0:00:46.504404

Epoch:3/20: step:1100, lr:0.0013896499, loss:0.004874791, elapsed_time:0:00:49.631911

Epoch:3/20: step:1200, lr:0.001344406, loss:0.004791951, elapsed_time:0:00:52.859733

Epoch:3/20: step:1300, lr:0.0013006352, loss:0.0022684378, elapsed_time:0:00:55.914907

Epoch:3/20: step:1400, lr:0.0012582893, loss:0.0038918357, elapsed_time:0:00:59.008944

Epoch:4/20: step:1500, lr:0.0012173222, loss:0.0032633797, elapsed_time:0:01:04.889177

Epoch:4/20: step:1600, lr:0.0011776891, loss:0.0037171482, elapsed_time:0:01:07.881083

Epoch:4/20: step:1700, lr:0.001139346, loss:0.023981912, elapsed_time:0:01:10.978614

Epoch:4/20: step:1800, lr:0.0011022515, loss:0.0034663263, elapsed_time:0:01:13.954130

Epoch:4/20: step:1900, lr:0.0010663647, loss:0.0036083574, elapsed_time:0:01:16.991969

Epoch:5/20: step:2000, lr:0.0010316462, loss:0.0019305379, elapsed_time:0:01:23.141658

Epoch:5/20: step:2100, lr:0.000998058, loss:0.0030456441, elapsed_time:0:01:26.350413

Epoch:5/20: step:2200, lr:0.00096556346, loss:0.0019726416, elapsed_time:0:01:31.440802

Epoch:5/20: step:2300, lr:0.0009341269, loss:0.003545585, elapsed_time:0:01:34.714006

Epoch:5/20: step:2400, lr:0.00090371387, loss:0.011892161, elapsed_time:0:01:37.877781

Epoch:6/20: step:2500, lr:0.0008742909, loss:0.0027134495, elapsed_time:0:01:44.344145

Epoch:6/20: step:2600, lr:0.00084582594, loss:0.0023118032, elapsed_time:0:01:47.462685

Epoch:6/20: step:2700, lr:0.0008182877, loss:0.0022492257, elapsed_time:0:01:50.685182

Epoch:6/20: step:2800, lr:0.0007916461, loss:0.0036151696, elapsed_time:0:01:53.853319

Epoch:6/20: step:2900, lr:0.00076587184, loss:0.0013429644, elapsed_time:0:01:57.150429

Epoch:7/20: step:3000, lr:0.0007409367, loss:0.002318274, elapsed_time:0:02:03.306859

Epoch:7/20: step:3100, lr:0.0007168135, loss:0.0031589153, elapsed_time:0:02:06.355756

Epoch:7/20: step:3200, lr:0.00069347565, loss:0.007980357, elapsed_time:0:02:10.185864

Epoch:7/20: step:3300, lr:0.0006708977, loss:0.0031447066, elapsed_time:0:02:13.496759

Epoch:7/20: step:3400, lr:0.00064905465, loss:0.0021871747, elapsed_time:0:02:16.778109

Epoch:8/20: step:3500, lr:0.00062792294, loss:0.0009328833, elapsed_time:0:02:23.160157

Epoch:8/20: step:3600, lr:0.00060747913, loss:0.0016194503, elapsed_time:0:02:26.127217

Epoch:8/20: step:3700, lr:0.0005877009, loss:0.0031733052, elapsed_time:0:02:29.507206

Epoch:8/20: step:3800, lr:0.0005685668, loss:0.0014325862, elapsed_time:0:02:32.676124

Epoch:8/20: step:3900, lr:0.0005500554, loss:0.0013745071, elapsed_time:0:02:35.741327

Epoch:9/20: step:4000, lr:0.0005321469, loss:0.002170659, elapsed_time:0:02:42.910293

Epoch:9/20: step:4100, lr:0.0005148214, loss:0.0015856312, elapsed_time:0:02:45.993163

Epoch:9/20: step:4200, lr:0.00049805985, loss:0.0011591299, elapsed_time:0:02:49.189550

Epoch:9/20: step:4300, lr:0.00048184418, loss:0.00094359077, elapsed_time:0:02:52.427817

Epoch:9/20: step:4400, lr:0.0004661564, loss:0.0018941778, elapsed_time:0:02:55.660717

Epoch:10/20: step:4500, lr:0.00045097942, loss:0.0017304551, elapsed_time:0:03:02.055713

Epoch:10/20: step:4600, lr:0.00043629648, loss:0.0012931156, elapsed_time:0:03:04.932044

Epoch:10/20: step:4700, lr:0.0004220917, loss:0.0021953098, elapsed_time:0:03:07.896947

Epoch:10/20: step:4800, lr:0.00040834935, loss:0.0017295917, elapsed_time:0:03:10.896882

Epoch:10/20: step:4900, lr:0.00039505432, loss:0.001161565, elapsed_time:0:03:13.889331

Epoch:11/20: step:5000, lr:0.00038219223, loss:0.0014073789, elapsed_time:0:03:20.462106

Epoch:11/20: step:5100, lr:0.00036974892, loss:0.0010836319, elapsed_time:0:03:23.682703

Epoch:11/20: step:5200, lr:0.00035771076, loss:0.00076902326, elapsed_time:0:03:26.869806

Epoch:11/20: step:5300, lr:0.00034606442, loss:0.0009307207, elapsed_time:0:03:30.008973

Epoch:11/20: step:5400, lr:0.00033479734, loss:0.0021400158, elapsed_time:0:03:32.917152

Epoch:12/20: step:5500, lr:0.0003238971, loss:0.0019386467, elapsed_time:0:03:39.093556

Epoch:12/20: step:5600, lr:0.00031335175, loss:0.0013063062, elapsed_time:0:03:42.008007

Epoch:12/20: step:5700, lr:0.00030314972, loss:0.002532655, elapsed_time:0:03:45.090217

Epoch:12/20: step:5800, lr:0.00029327985, loss:0.0016296385, elapsed_time:0:03:48.691198

Epoch:13/20: step:5900, lr:0.0002837313, loss:0.0006595646, elapsed_time:0:03:54.842493

Epoch:13/20: step:6000, lr:0.00027449362, loss:0.002746162, elapsed_time:0:03:57.964573

Epoch:13/20: step:6100, lr:0.0002655567, loss:0.002911101, elapsed_time:0:04:01.137798

Epoch:13/20: step:6200, lr:0.0002569108, loss:0.0011877972, elapsed_time:0:04:04.564487

Epoch:13/20: step:6300, lr:0.00024854633, loss:0.0014408195, elapsed_time:0:04:07.732720

Epoch:14/20: step:6400, lr:0.00024045425, loss:0.0005916285, elapsed_time:0:04:13.580777

Epoch:14/20: step:6500, lr:0.00023262555, loss:0.0010243907, elapsed_time:0:04:16.652094

Epoch:14/20: step:6600, lr:0.00022505183, loss:0.0012447721, elapsed_time:0:04:19.611911

Epoch:14/20: step:6700, lr:0.00021772462, loss:0.0013344113, elapsed_time:0:04:22.680885

Epoch:14/20: step:6800, lr:0.00021063598, loss:0.00095152075, elapsed_time:0:04:25.699981

Epoch:15/20: step:6900, lr:0.00020377815, loss:0.0013683513, elapsed_time:0:04:32.497641

Epoch:15/20: step:7000, lr:0.00019714358, loss:0.000937992, elapsed_time:0:04:35.556172

Epoch:15/20: step:7100, lr:0.000190725, loss:0.0011208535, elapsed_time:0:04:39.522118

Epoch:15/20: step:7200, lr:0.00018451545, loss:0.0013968248, elapsed_time:0:04:42.613237

Epoch:15/20: step:7300, lr:0.00017850802, loss:0.001865882, elapsed_time:0:04:45.913797

Epoch:16/20: step:7400, lr:0.0001726962, loss:0.00086634327, elapsed_time:0:04:52.281148

Epoch:16/20: step:7500, lr:0.00016707358, loss:0.00090147194, elapsed_time:0:04:55.271719

Epoch:16/20: step:7600, lr:0.00016163407, loss:0.00086613244, elapsed_time:0:04:58.307988

Epoch:16/20: step:7700, lr:0.00015637162, loss:0.0011080066, elapsed_time:0:05:01.361439

Epoch:16/20: step:7800, lr:0.00015128049, loss:0.0006235113, elapsed_time:0:05:04.622269

Epoch:17/20: step:7900, lr:0.00014635516, loss:0.0007266796, elapsed_time:0:05:10.700736

Epoch:17/20: step:8000, lr:0.00014159014, loss:0.0007338189, elapsed_time:0:05:13.946375

Epoch:17/20: step:8100, lr:0.00013698026, loss:0.0019856642, elapsed_time:0:05:17.120042

Epoch:17/20: step:8200, lr:0.00013252054, loss:0.0007488798, elapsed_time:0:05:20.250201

Epoch:17/20: step:8300, lr:0.00012820594, loss:0.0013653042, elapsed_time:0:05:23.463415

Epoch:18/20: step:8400, lr:0.00012403181, loss:0.0010307662, elapsed_time:0:05:29.359869

Epoch:18/20: step:8500, lr:0.00011999363, loss:0.0012134392, elapsed_time:0:05:32.419069

Epoch:18/20: step:8600, lr:0.00011608689, loss:0.0011678414, elapsed_time:0:05:35.702287

Epoch:18/20: step:8700, lr:0.000112307374, loss:0.00057145173, elapsed_time:0:05:38.663528

Epoch:18/20: step:8800, lr:0.00010865089, loss:0.0009809344, elapsed_time:0:05:41.760313

Epoch:19/20: step:8900, lr:0.00010511347, loss:0.00085311267, elapsed_time:0:05:47.697741

Epoch:19/20: step:9000, lr:0.000101691214, loss:0.0008098744, elapsed_time:0:05:50.658137

Epoch:19/20: step:9100, lr:9.838038e-05, loss:0.0009824175, elapsed_time:0:05:53.668848

Epoch:19/20: step:9200, lr:9.517731e-05, loss:0.00084420526, elapsed_time:0:05:56.730936

Epoch:19/20: step:9300, lr:9.2078575e-05, loss:0.00097442465, elapsed_time:0:05:59.702544

Epoch:20/20: step:9400, lr:8.90807e-05, loss:0.0010794926, elapsed_time:0:06:05.764290

Epoch:20/20: step:9500, lr:8.618041e-05, loss:0.00093487825, elapsed_time:0:06:09.993163

Epoch:20/20: step:9600, lr:8.337459e-05, loss:0.000790352, elapsed_time:0:06:13.247832

Epoch:20/20: step:9700, lr:8.066008e-05, loss:0.00086212135, elapsed_time:0:06:16.309918

Epoch:20/20: step:9800, lr:7.8033954e-05, loss:0.001053803, elapsed_time:0:06:19.429928

Epoch:20/20: step:9820, lr:7.7519086e-05, loss:0.00077667, elapsed_time:0:06:20.014907

