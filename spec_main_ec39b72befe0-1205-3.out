WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
source_pan_data shape: (1296, 264, 264, 1)
gt_data shape: (1296, 264, 264, 4)
data shape: (1296, 264, 264, 5)
Epoches: 50, Batch_size: 10
Train images number 1296, Batches: 129.

Train set has been trimmed 6 samples...

2021-12-05 10:42:39.414503: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-05 10:42:41.121802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0
2021-12-05 10:42:41.123703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38414 MB memory:  -> device: 1, name: A100-PCIE-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0
2021-12-05 10:42:41.125468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38414 MB memory:  -> device: 2, name: A100-PCIE-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0
2021-12-05 10:42:41.127219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38414 MB memory:  -> device: 3, name: A100-PCIE-40GB, pci bus id: 0000:c2:00.0, compute capability: 8.0
out shape: (10, 66, 66, 4)
2021-12-05 10:42:43.628720: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301
Epoch:1/50: step:100, lr:0.0017632586, loss:0.13877955, elapsed_time:0:00:09.887544

Epoch:2/50: step:200, lr:0.0015545404, loss:0.050955594, elapsed_time:0:00:14.312452

Epoch:3/50: step:300, lr:0.0013705282, loss:0.02852433, elapsed_time:0:00:18.566985

Epoch:4/50: step:400, lr:0.0012082979, loss:0.019100996, elapsed_time:0:00:22.736016

Epoch:4/50: step:500, lr:0.0010652709, loss:0.015883468, elapsed_time:0:00:26.263210

Epoch:5/50: step:600, lr:0.0009391739, loss:0.013577286, elapsed_time:0:00:30.470847

Epoch:6/50: step:700, lr:0.00082800316, loss:0.0128150275, elapsed_time:0:00:34.588377

Epoch:7/50: step:800, lr:0.0007299919, loss:0.011442266, elapsed_time:0:00:38.654406

Epoch:7/50: step:900, lr:0.00064358214, loss:0.010938471, elapsed_time:0:00:42.116906

Epoch:8/50: step:1000, lr:0.0005674008, loss:0.010889338, elapsed_time:0:00:46.172643

Epoch:9/50: step:1100, lr:0.00050023716, loss:0.009657101, elapsed_time:0:00:50.340073

Epoch:10/50: step:1200, lr:0.00044102382, loss:0.009746962, elapsed_time:0:00:54.430439

Epoch:11/50: step:1300, lr:0.00038881946, loss:0.008542417, elapsed_time:0:00:58.510468

Epoch:11/50: step:1400, lr:0.00034279455, loss:0.008259853, elapsed_time:0:01:02.100595

Epoch:12/50: step:1500, lr:0.00030221776, loss:0.008082162, elapsed_time:0:01:06.272837

Epoch:13/50: step:1600, lr:0.00026644408, loss:0.007805832, elapsed_time:0:01:10.406572

Epoch:14/50: step:1700, lr:0.00023490489, loss:0.00787735, elapsed_time:0:01:14.510113

Epoch:14/50: step:1800, lr:0.00020709902, loss:0.007841049, elapsed_time:0:01:18.007823

Epoch:15/50: step:1900, lr:0.00018258454, loss:0.007612588, elapsed_time:0:01:22.160459

Epoch:16/50: step:2000, lr:0.00016097186, loss:0.007473334, elapsed_time:0:01:26.365259

Epoch:17/50: step:2100, lr:0.00014191751, loss:0.0073871654, elapsed_time:0:01:30.518800

Epoch:18/50: step:2200, lr:0.0001251186, loss:0.0071518514, elapsed_time:0:01:34.641855

Epoch:18/50: step:2300, lr:0.000110308225, loss:0.006961981, elapsed_time:0:01:38.150804

Epoch:19/50: step:2400, lr:9.7250995e-05, loss:0.0069601517, elapsed_time:0:01:42.352877

Epoch:20/50: step:2500, lr:8.573932e-05, loss:0.006520773, elapsed_time:0:01:46.539096

Epoch:21/50: step:2600, lr:7.559029e-05, loss:0.006410472, elapsed_time:0:01:50.729504

Epoch:21/50: step:2700, lr:6.6642606e-05, loss:0.0068135704, elapsed_time:0:01:54.299659

Epoch:22/50: step:2800, lr:5.8754056e-05, loss:0.0065871268, elapsed_time:0:01:58.432227

Epoch:23/50: step:2900, lr:5.179931e-05, loss:0.006163997, elapsed_time:0:02:02.554589

Epoch:24/50: step:3000, lr:4.5667788e-05, loss:0.0063486947, elapsed_time:0:02:06.751627

Epoch:25/50: step:3100, lr:4.0262054e-05, loss:0.006211565, elapsed_time:0:02:10.956364

Epoch:25/50: step:3200, lr:3.5496214e-05, loss:0.006251367, elapsed_time:0:02:14.510365

Epoch:26/50: step:3300, lr:3.129449e-05, loss:0.0062773665, elapsed_time:0:02:18.728895

Epoch:27/50: step:3400, lr:2.7590148e-05, loss:0.006278528, elapsed_time:0:02:22.946913

Epoch:28/50: step:3500, lr:2.4324283e-05, loss:0.0060502263, elapsed_time:0:02:27.142339

Epoch:28/50: step:3600, lr:2.1444997e-05, loss:0.005958467, elapsed_time:0:02:30.691683

Epoch:29/50: step:3700, lr:1.8906536e-05, loss:0.006198652, elapsed_time:0:02:34.829272

Epoch:30/50: step:3800, lr:1.6668555e-05, loss:0.0062171244, elapsed_time:0:02:39.137916

Epoch:31/50: step:3900, lr:1.4695488e-05, loss:0.00601474, elapsed_time:0:02:43.339304

Epoch:32/50: step:4000, lr:1.295597e-05, loss:0.0061364416, elapsed_time:0:02:47.554481

Epoch:32/50: step:4100, lr:1.1422362e-05, loss:0.0060197273, elapsed_time:0:02:51.067574

Epoch:33/50: step:4200, lr:1.0070288e-05, loss:0.006100621, elapsed_time:0:02:55.298977

Epoch:34/50: step:4300, lr:8.878263e-06, loss:0.0060763415, elapsed_time:0:02:59.547415

Epoch:35/50: step:4400, lr:7.827334e-06, loss:0.005977218, elapsed_time:0:03:03.756568

Epoch:35/50: step:4500, lr:6.900808e-06, loss:0.0061410824, elapsed_time:0:03:07.353038

Epoch:36/50: step:4600, lr:6.0839525e-06, loss:0.00570485, elapsed_time:0:03:11.509073

Epoch:37/50: step:4700, lr:5.363791e-06, loss:0.005828264, elapsed_time:0:03:15.804023

Epoch:38/50: step:4800, lr:4.728878e-06, loss:0.0058377795, elapsed_time:0:03:19.982356

Epoch:38/50: step:4900, lr:4.1691146e-06, loss:0.005781632, elapsed_time:0:03:23.386953

Epoch:39/50: step:5000, lr:3.6756153e-06, loss:0.0061344802, elapsed_time:0:03:27.622946

Epoch:40/50: step:5100, lr:3.240528e-06, loss:0.0058150874, elapsed_time:0:03:31.743690

Epoch:41/50: step:5200, lr:2.856946e-06, loss:0.005858285, elapsed_time:0:03:35.872839

Epoch:42/50: step:5300, lr:2.5187671e-06, loss:0.0058031613, elapsed_time:0:03:40.039269

Epoch:42/50: step:5400, lr:2.2206186e-06, loss:0.006076567, elapsed_time:0:03:43.540255

Epoch:43/50: step:5500, lr:1.9577624e-06, loss:0.0056669824, elapsed_time:0:03:47.673836

Epoch:44/50: step:5600, lr:1.7260195e-06, loss:0.0057821744, elapsed_time:0:03:51.818149

Epoch:45/50: step:5700, lr:1.5217103e-06, loss:0.005883895, elapsed_time:0:03:56.006854

Epoch:45/50: step:5800, lr:1.3415843e-06, loss:0.006190842, elapsed_time:0:03:59.569191

Epoch:46/50: step:5900, lr:1.1827797e-06, loss:0.0058858697, elapsed_time:0:04:03.723971

Epoch:47/50: step:6000, lr:1.0427734e-06, loss:0.0060419766, elapsed_time:0:04:07.900272

Epoch:48/50: step:6100, lr:9.1933936e-07, loss:0.005766635, elapsed_time:0:04:12.050475

Epoch:49/50: step:6200, lr:8.105166e-07, loss:0.0060737366, elapsed_time:0:04:16.215868

Epoch:49/50: step:6300, lr:7.145752e-07, loss:0.005842113, elapsed_time:0:04:19.727793

Epoch:50/50: step:6400, lr:6.2999055e-07, loss:0.0058095637, elapsed_time:0:04:23.933589

Epoch:50/50: step:6450, lr:5.9153007e-07, loss:0.005989098, elapsed_time:0:04:25.590493

