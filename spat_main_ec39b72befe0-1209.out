WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
source_pan_data shape: (1296, 264, 264, 1)
gt_data shape: (1296, 264, 264, 4)
data shape: (1296, 264, 264, 5)
Epoches: 30, Batch_size: 10
Train images number 1296, Batches: 129.

Train set has been trimmed 6 samples...

2021-12-09 03:42:27.624405: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-09 03:42:29.327319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0
2021-12-09 03:42:29.329242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38414 MB memory:  -> device: 1, name: A100-PCIE-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0
2021-12-09 03:42:29.331010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38414 MB memory:  -> device: 2, name: A100-PCIE-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0
2021-12-09 03:42:29.332809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38414 MB memory:  -> device: 3, name: A100-PCIE-40GB, pci bus id: 0000:c2:00.0, compute capability: 8.0
out shape: (10, 264, 264, 1)
2021-12-09 03:42:31.539081: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301
Epoch:1/30: step:100, lr:0.0017632586, loss:0.0084253205, elapsed_time:0:00:18.364390

Epoch:2/30: step:200, lr:0.0015545404, loss:0.0011957723, elapsed_time:0:00:29.245451

Epoch:3/30: step:300, lr:0.0013705282, loss:0.00081148616, elapsed_time:0:00:40.104244

Epoch:4/30: step:400, lr:0.0012082979, loss:0.00062439335, elapsed_time:0:00:51.001478

Epoch:4/30: step:500, lr:0.0010652709, loss:0.0005755562, elapsed_time:0:01:01.346373

Epoch:5/30: step:600, lr:0.0009391739, loss:0.0004860113, elapsed_time:0:01:12.126018

Epoch:6/30: step:700, lr:0.00082800316, loss:0.00047649432, elapsed_time:0:01:22.987376

Epoch:7/30: step:800, lr:0.0007299919, loss:0.00039431223, elapsed_time:0:01:33.890506

Epoch:7/30: step:900, lr:0.00064358214, loss:0.00037328078, elapsed_time:0:01:44.199610

Epoch:8/30: step:1000, lr:0.0005674008, loss:0.0003683935, elapsed_time:0:01:55.137891

Epoch:9/30: step:1100, lr:0.00050023716, loss:0.0003461368, elapsed_time:0:02:06.042612

Epoch:10/30: step:1200, lr:0.00044102382, loss:0.00032709198, elapsed_time:0:02:17.004682

Epoch:11/30: step:1300, lr:0.00038881946, loss:0.00032351917, elapsed_time:0:02:27.903542

Epoch:11/30: step:1400, lr:0.00034279455, loss:0.00031227767, elapsed_time:0:02:38.238544

Epoch:12/30: step:1500, lr:0.00030221776, loss:0.00031432472, elapsed_time:0:02:49.182673

Epoch:13/30: step:1600, lr:0.00026644408, loss:0.000288077, elapsed_time:0:03:00.215313

Epoch:14/30: step:1700, lr:0.00023490489, loss:0.00029542774, elapsed_time:0:03:11.229560

Epoch:14/30: step:1800, lr:0.00020709902, loss:0.00028093695, elapsed_time:0:03:21.581529

Epoch:15/30: step:1900, lr:0.00018258454, loss:0.00028839707, elapsed_time:0:03:32.485427

Epoch:16/30: step:2000, lr:0.00016097186, loss:0.00027925253, elapsed_time:0:03:43.387162

Epoch:17/30: step:2100, lr:0.00014191751, loss:0.0002726118, elapsed_time:0:03:54.227814

Epoch:18/30: step:2200, lr:0.0001251186, loss:0.00026466054, elapsed_time:0:04:05.086172

Epoch:18/30: step:2300, lr:0.000110308225, loss:0.00026252453, elapsed_time:0:04:15.468317

Epoch:19/30: step:2400, lr:9.7250995e-05, loss:0.00028007122, elapsed_time:0:04:26.421172

Epoch:20/30: step:2500, lr:8.573932e-05, loss:0.0002776293, elapsed_time:0:04:37.351106

Epoch:21/30: step:2600, lr:7.559029e-05, loss:0.0002515454, elapsed_time:0:04:48.289790

Epoch:21/30: step:2700, lr:6.6642606e-05, loss:0.0002612966, elapsed_time:0:04:58.575904

Epoch:22/30: step:2800, lr:5.8754056e-05, loss:0.0002663483, elapsed_time:0:05:09.593285

Epoch:23/30: step:2900, lr:5.179931e-05, loss:0.0002692396, elapsed_time:0:05:20.452788

Epoch:24/30: step:3000, lr:4.5667788e-05, loss:0.0002542463, elapsed_time:0:05:31.387863

Epoch:25/30: step:3100, lr:4.0262054e-05, loss:0.00026330643, elapsed_time:0:05:42.253769

Epoch:25/30: step:3200, lr:3.5496214e-05, loss:0.00025310722, elapsed_time:0:05:52.552103

Epoch:26/30: step:3300, lr:3.129449e-05, loss:0.00025288604, elapsed_time:0:06:03.487003

Epoch:27/30: step:3400, lr:2.7590148e-05, loss:0.00026603977, elapsed_time:0:06:14.436419

Epoch:28/30: step:3500, lr:2.4324283e-05, loss:0.0002610962, elapsed_time:0:06:25.448096

Epoch:28/30: step:3600, lr:2.1444997e-05, loss:0.0002451322, elapsed_time:0:06:35.737012

Epoch:29/30: step:3700, lr:1.8906536e-05, loss:0.00024313501, elapsed_time:0:06:46.733597

Epoch:30/30: step:3800, lr:1.6668555e-05, loss:0.000251431, elapsed_time:0:06:57.753573

Epoch:30/30: step:3870, lr:1.526153e-05, loss:0.0002557526, elapsed_time:0:07:05.007579

